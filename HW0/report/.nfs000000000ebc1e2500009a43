\documentclass[10pt, a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{charter}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{url}
\usepackage{array}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage[nocompress]{cite}
\usepackage{geometry}
\geometry{top=1.3cm,bottom=1.3cm,left=1.6cm,right=1.5cm}

\pagestyle{plain}

\begin{document}

\begin{center}

\textbf{Introduction to Computer Vision -- Homework 0} \\[0.1cm]

\textbf{RA192617 -- Edgar Rodolfo Quispe Condori} \\[0.1cm]
\textbf{RA192618 -- Darwin Ttito Concha} \\[0.1cm]

Institute of Computing, University of Campinas (UNICAMP) \\
Campinas-SP, Brazil, 13083-852 \\
\end{center}

\section{Input images}
We consider 4 input images of different sizes.
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../input/p0-1-0.jpg}
  \caption{Figura 1. Input p0-1-0.jpg, 207x236 pixels}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../input/p0-1-1.jpg}
  \caption{Figura 2. Input p0-1-1.jpg, 183x275 pixels}
  \label{fig:sfig2}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../input/p0-1-2.jpg}
  \caption{Figura 3. Input p0-1-2.jpg, 272x384 pixels}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../input/p0-1-3.jpg}
  \caption{Figura 4. Input p0-1-3.jpg, 390x502 pixels}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}

\section{Color planes}
The report shows the results for the first two images, while the code generates results for the four input images.
\begin{enumerate}[label=\emph{\alph*)}]
\item Swap the red and blue channels of the input image.
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-a-0.jpg}
  \caption{Figura 5. Output for the input p0-1-0.jpg}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-a-1.jpg}
  \caption{Figura 6. Output for the input p0-1-1.jpg}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}
\\\\The imread() instruction of OpenCV reads images in format BGR, then we have to swap the channel blue(first channel) with the channel red(third channel), generating a new image in RGB format.\\We can see that the red colored regions become blue colored regions and the blue colored regions become  red colored regions

\item Create a monochrome image (img-green) by selecting the green channel of the input image.
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-b-0.jpg}
  \caption{Figura 7. Output for the input p0-1-0.jpg}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-b-1.jpg}
  \caption{Figura 8. Output for the input p0-1-1.jpg}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}
\\As we extract the green channel from the original image to generate a monochromatic image, then, the regions of the image that depend more on green color will have values close to 255 in the channel green, which means that in the output image those regions will have a color close to white, while the other regions of the image will have a color close to black.

\item Create a monochrome image (img-red) by selecting the red channel of the first input image.
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-c-0.jpg}
  \caption{Figura 9. Output for the input p0-1-0.jpg}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-2-c-1.jpg}
  \caption{Figura 10. Output for the input p0-1-1.jpg}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}
\\Similar to the previous interpretation, we say that the light colored regions in the output image are red colored regions in the original image.
\item Which image looks more like what you would expect a monochrome image to look like? Would you
expect a computer vision algorithm to work on one better than the other? Why?
\begin{enumerate}[label=\digit*)]
\item The first item
\item The second item
\item The third etc 
\end{enumerate}
\end{enumerate}

\section{Replacements of pixels.}
\begin{enumerate}[label={(\arabic*)}]
\item Lets call the monochrome image from your answer to the last item of the previous
question A, and the other one B. Take the center square region of 100 x 100 pixels of A and insert it into the center of B.
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-3-a-0.jpg}
  \caption{Figura 11. Output for the input p0-1-0.jpg}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-3-a-1.jpg}
  \caption{Figura 12. Output for the input p0-1-1.jpg}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}

\item Replace the respective channel of B into the original image
\begin{figure}[h!]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-3-b-0.jpg}
  \caption{Figura 13. Output for the input p0-1-0.jpg}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=0.7\linewidth]{../output/p0-3-b-1.jpg}
  \caption{Figura 14. Output for the input p0-1-1.jpg}
  \label{fig:sfig2}
\end{subfigure}
\label{fig:fig}
\end{figure}
\end{enumerate}

\end{document}
